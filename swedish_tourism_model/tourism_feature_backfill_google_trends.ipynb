{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c08b35-116c-4177-a3b4-b315118eadde",
   "metadata": {},
   "source": [
    "# Feature Backfill for Google Trends\n",
    "**Goal of this notebook**\n",
    "\n",
    "This notebook will backfill the feature groups containing google trends data and the flight data\n",
    "* Supports backfill\n",
    "* Produces daily features\n",
    "* Is point-in-time correct\n",
    "* Uploads features to Hopsworks Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231ed7d-87d0-4ad7-9a1c-0c42cf422c25",
   "metadata": {},
   "source": [
    "**Imports & setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7c1722-87f8-4e74-8df7-33336b14934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import asyncio\n",
    "\n",
    "# Google Trends\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "# Hopsworks\n",
    "import hopsworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc1f36a-c5b3-4cce-aa46-67e478ac67cc",
   "metadata": {},
   "source": [
    "## Google Trends Feature Backfilll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ae773-9f15-40eb-b9e7-7aab7d9eea1f",
   "metadata": {},
   "source": [
    "### Feature Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a311969e-676f-49bf-a707-f5b85e902636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search terms used as predictors\n",
    "KEYWORDS = [\n",
    "    \"vikings\",\n",
    "    \"fika\",\n",
    "    \"stockholm\",\n",
    "    \"ikea\",\n",
    "    \"abba\"\n",
    "]\n",
    "\n",
    "# Country code for Sweden\n",
    "COUNTRY = \"SE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24112896-f394-43fc-9320-8bad5b2778c3",
   "metadata": {},
   "source": [
    "### Backfill Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a62d73-b220-46af-b740-845631dde57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature pipeline from 2019-12-31 to 2025-12-27\n"
     ]
    }
   ],
   "source": [
    "# Backfill range (used only in backfill mode)\n",
    "start_date = date(2019, 12, 31)\n",
    "end_date   = date(2025, 12, 27)\n",
    "\n",
    "print(f\"Running feature pipeline from {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8b34c-2610-426b-84bf-3f29bdc2c711",
   "metadata": {},
   "source": [
    "### Fetch Google Trends Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8982f27-d9d2-4590-9caa-87f4a99190b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_google_trends_daily(keywords, start_date, end_date):\n",
    "    pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "    all_data = []\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    while start_date < end_date:\n",
    "        window_end = min(start_date + pd.Timedelta(days=89), end_date)\n",
    "\n",
    "        pytrends.build_payload(\n",
    "            kw_list=keywords,\n",
    "            timeframe=f\"{start_date:%Y-%m-%d} {window_end:%Y-%m-%d}\",\n",
    "            geo=COUNTRY\n",
    "        )\n",
    "\n",
    "        df = pytrends.interest_over_time()\n",
    "        if not df.empty:\n",
    "            df = df[~df[\"isPartial\"]]\n",
    "            all_data.append(df)\n",
    "\n",
    "        start_date = window_end + pd.Timedelta(days=1)\n",
    "\n",
    "    return pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203fca9-1b7c-4ab3-b9f4-01078c34c492",
   "metadata": {},
   "source": [
    "### Clean and resample to Daily Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f907bc95-28cc-4612-84b4-4c5166a7cb6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTooManyRequestsError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Fetch raw data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m raw_trends = \u001b[43mfetch_google_trends_daily\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKEYWORDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Remove partial rows (important!)\u001b[39;00m\n\u001b[32m      5\u001b[39m raw_trends = raw_trends[raw_trends[\u001b[33m\"\u001b[39m\u001b[33misPartial\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[38;5;28;01mFalse\u001b[39;00m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mfetch_google_trends_daily\u001b[39m\u001b[34m(keywords, start_date, end_date)\u001b[39m\n\u001b[32m      9\u001b[39m window_end = \u001b[38;5;28mmin\u001b[39m(start_date + pd.Timedelta(days=\u001b[32m89\u001b[39m), end_date)\n\u001b[32m     11\u001b[39m pytrends.build_payload(\n\u001b[32m     12\u001b[39m     kw_list=keywords,\n\u001b[32m     13\u001b[39m     timeframe=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m%Y-%m-%d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_end\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m%Y-%m-%d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     geo=COUNTRY\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df = \u001b[43mpytrends\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.empty:\n\u001b[32m     19\u001b[39m     df = df[~df[\u001b[33m\"\u001b[39m\u001b[33misPartial\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aq/lib/python3.11/site-packages/pytrends/request.py:232\u001b[39m, in \u001b[36mTrendReq.interest_over_time\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m over_time_payload = {\n\u001b[32m    225\u001b[39m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[32m    226\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreq\u001b[39m\u001b[33m'\u001b[39m: json.dumps(\u001b[38;5;28mself\u001b[39m.interest_over_time_widget[\u001b[33m'\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m'\u001b[39m]),\n\u001b[32m    227\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.interest_over_time_widget[\u001b[33m'\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    228\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtz\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.tz\n\u001b[32m    229\u001b[39m }\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m req_json = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTrendReq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTrendReq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m df = pd.DataFrame(req_json[\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtimelineData\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (df.empty):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aq/lib/python3.11/site-packages/pytrends/request.py:159\u001b[39m, in \u001b[36mTrendReq._get_data\u001b[39m\u001b[34m(self, url, method, trim_chars, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == status_codes.codes.too_many_requests:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TooManyRequestsError.from_response(response)\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.ResponseError.from_response(response)\n",
      "\u001b[31mTooManyRequestsError\u001b[39m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "# Fetch raw data\n",
    "raw_trends = fetch_google_trends_daily(KEYWORDS, start_date, end_date)\n",
    "\n",
    "# Remove partial rows (important!)\n",
    "raw_trends = raw_trends[raw_trends[\"isPartial\"] == False]\n",
    "\n",
    "# Drop metadata column\n",
    "raw_trends = raw_trends.drop(columns=[\"isPartial\"])\n",
    "\n",
    "# Convert to daily frequency using forward-fill\n",
    "daily_trends = (\n",
    "    raw_trends\n",
    "    .resample(\"D\")\n",
    "    .ffill()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ensure proper datetime + ordering BEFORE rolling\n",
    "daily_trends[\"date\"] = pd.to_datetime(daily_trends[\"date\"], errors=\"coerce\").dt.normalize()\n",
    "daily_trends = daily_trends.sort_values(\"date\")\n",
    "\n",
    "daily_trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09724732-b9ba-4739-9c1a-fe82b6d3acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['city'] = \"Märsta\"\n",
    "\n",
    "missing_days = pd.to_datetime([\n",
    "    '2023-12-02',\n",
    "    '2023-12-03',\n",
    "    '2023-12-04'\n",
    "])\n",
    "\n",
    "features_df = features_df[~features_df['date'].isin(missing_days)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c3b817-c7cd-406e-b839-24aebc0e8f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2179 entries, 7 to 2188\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              2179 non-null   datetime64[ns]\n",
      " 1   vikings           2179 non-null   int64         \n",
      " 2   fika              2179 non-null   int64         \n",
      " 3   stockholm         2179 non-null   int64         \n",
      " 4   ikea              2179 non-null   int64         \n",
      " 5   abba              2179 non-null   int64         \n",
      " 6   vikings_7d_avg    2179 non-null   float64       \n",
      " 7   fika_7d_avg       2179 non-null   float64       \n",
      " 8   stockholm_7d_avg  2179 non-null   float64       \n",
      " 9   ikea_7d_avg       2179 non-null   float64       \n",
      " 10  abba_7d_avg       2179 non-null   float64       \n",
      " 11  city              2179 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(5), int64(5), object(1)\n",
      "memory usage: 221.3+ KB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bdd96f-f410-443d-ad12-55c43cc9eb48",
   "metadata": {},
   "source": [
    "### Connect to Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928adbd5-7209-40c6-9ddc-d02cd0e041a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-06 09:26:51,296 INFO: Initializing external client\n",
      "2026-01-06 09:26:51,298 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-06 09:26:53,142 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286325\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b47084-21a8-42c2-ac46-a1d0c8af6920",
   "metadata": {},
   "source": [
    "### Create/get Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986fd7eb-a930-43e7-bbac-09579ed0f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = fs.get_or_create_feature_group(\n",
    "    name=\"google_trends_daily\",\n",
    "    version=1,\n",
    "    primary_key=['city'],\n",
    "    event_time=\"date\",\n",
    "    description=\"Daily Google Trends features for Sweden tourism prediction\",\n",
    "    online_enabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255d07e-2f77-43f0-a0b1-a7a28160f893",
   "metadata": {},
   "source": [
    "### Write features to Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e33b57-23f2-48c9-8269-5f3d57ac129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286325/fs/1265794/fg/1893830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |█| Rows 2179/2179 | Elapsed Time: 00:00 | Remainin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: google_trends_daily_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286325/jobs/named/google_trends_daily_1_offline_fg_materialization/executions\n",
      "2026-01-06 09:27:55,890 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-06 09:27:59,087 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-06 09:29:51,289 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-06 09:30:00,011 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('google_trends_daily_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(\n",
    "    features_df,\n",
    "    write_options={\"wait_for_job\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd60c65-4884-4ce4-b942-4758f33695ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tog bort feature engineeringen nu för vet inte var den ska ligga någonstans. Om den ligger här måste man också köra den i daily feature pipeline. \n",
    "Och i daily feature pipeline behövs data från tidigare dagar för att beräkna dom ny fieldsen. \n",
    "\n",
    "features_df = daily_trends.copy()\n",
    "\n",
    "for kw in KEYWORDS:\n",
    "    # Rolling averages\n",
    "    for window in ROLLING_WINDOWS:\n",
    "        features_df[f\"{kw}_{window}d_avg\"] = (\n",
    "            features_df[kw]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "    # Weekly change\n",
    "    features_df[f\"{kw}_7d_delta\"] = (\n",
    "        features_df[kw] - features_df[kw].shift(7)\n",
    "    )\n",
    "\n",
    "features_df.head()\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
